{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "import dlc_practical_prologue as prologue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden1 = nn.Linear(392, 256, bias=False)\n",
    "        self.hidden1_bn = nn.BatchNorm1d(256)\n",
    "        self.hidden2 = nn.Linear(256, 256, bias=False)\n",
    "        self.hidden2_bn = nn.BatchNorm1d(256)\n",
    "        self.output = nn.Linear(256, 2, bias=False)\n",
    "        self.output_bn = nn.BatchNorm1d(2)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.hidden1_bn(self.hidden1(x))\n",
    "        x = self.hidden2_bn(self.hidden2(F.relu(x)))\n",
    "        x = self.output_bn(self.output(F.relu(x)))\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        nb_hidden = 200\n",
    "        self.conv1 = nn.Conv2d(2, 32, kernel_size=5, padding = 3)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5, padding = 3)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=2)\n",
    "        self.fc1 = nn.Linear(1024, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.size())\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2))\n",
    "        #print(x.size())\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2))\n",
    "        #print(x.size())\n",
    "        x = F.relu(self.conv3(x))\n",
    "        #print(x.size())\n",
    "        x = F.relu(self.fc1(x.view(-1, 1024)))\n",
    "        #print(x.size())\n",
    "        x = self.fc2(x)\n",
    "        #print(x.size())\n",
    "        return F.log_softmax(x, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #optimizer = optim.SGD(model.parameters(), lr = 1e-2)\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 1e-4)\n",
    "    nb_epochs = 25\n",
    "\n",
    "    for e in range(nb_epochs):\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        nb_train_errors = compute_nb_errors(model, train_input, train_target)\n",
    "        print('train_error', nb_train_errors)\n",
    "        print('loss', loss.item())\n",
    "\n",
    "def compute_nb_errors(model, data_input, data_target):\n",
    "\n",
    "    nb_data_errors = 0\n",
    "\n",
    "    for b in range(0, data_input.size(0), mini_batch_size):\n",
    "        output = model(data_input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = torch.max(output.data, 1)\n",
    "        for k in range(mini_batch_size):\n",
    "            if data_target.data[b + k] != predicted_classes[k]:\n",
    "                nb_data_errors = nb_data_errors + 1\n",
    "    return nb_data_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_error 436\n",
      "loss 0.7340800762176514\n",
      "train_error 309\n",
      "loss 0.553303599357605\n",
      "train_error 233\n",
      "loss 0.46417683362960815\n",
      "train_error 189\n",
      "loss 0.42474380135536194\n",
      "train_error 164\n",
      "loss 0.4004661440849304\n",
      "train_error 146\n",
      "loss 0.3753364086151123\n",
      "train_error 123\n",
      "loss 0.34730806946754456\n",
      "train_error 118\n",
      "loss 0.3202071487903595\n",
      "train_error 101\n",
      "loss 0.29634183645248413\n",
      "train_error 84\n",
      "loss 0.2717239260673523\n",
      "train_error 75\n",
      "loss 0.2512671649456024\n",
      "train_error 60\n",
      "loss 0.2309439778327942\n",
      "train_error 53\n",
      "loss 0.2125740647315979\n",
      "train_error 43\n",
      "loss 0.19083130359649658\n",
      "train_error 36\n",
      "loss 0.17270280420780182\n",
      "train_error 27\n",
      "loss 0.15573744475841522\n",
      "train_error 22\n",
      "loss 0.13866744935512543\n",
      "train_error 19\n",
      "loss 0.12342708557844162\n",
      "train_error 15\n",
      "loss 0.1078970804810524\n",
      "train_error 14\n",
      "loss 0.09531532973051071\n",
      "train_error 12\n",
      "loss 0.08284351974725723\n",
      "train_error 10\n",
      "loss 0.07211553305387497\n",
      "train_error 10\n",
      "loss 0.062252312898635864\n",
      "train_error 10\n",
      "loss 0.05471329763531685\n",
      "train_error 13\n",
      "loss 0.0485171303153038\n",
      "train error (1.3,)\n",
      "test error Net 21.90% 219/1000\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target = Variable(train_input), Variable(train_target)\n",
    "test_input, test_target = Variable(test_input), Variable(test_target)\n",
    "\n",
    "mini_batch_size = 100\n",
    "\n",
    "for k in range(1):\n",
    "    model = Net2()\n",
    "    train_model(model, train_input, train_target)\n",
    "    nb_train_errors = compute_nb_errors(model, train_input, train_target) / train_input.size(0) * 100,\n",
    "    nb_test_errors = compute_nb_errors(model, test_input, test_target)\n",
    "    print('train error', nb_train_errors)\n",
    "    print('test error Net {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                      nb_test_errors, test_input.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
